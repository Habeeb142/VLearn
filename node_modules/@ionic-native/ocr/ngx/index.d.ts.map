{"version":3,"file":"index.d.ts","sources":["index.d.ts"],"names":[],"mappings":"AAAA;;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA","sourcesContent":["import { IonicNativePlugin } from '@ionic-native/core';\nexport declare enum OCRSourceType {\n    /**\n     * Normal processing from a file URL. This is the overall recommended choice\n     * for most applications. The distinction between file and native URLs is\n     * only relevant on iOS; under Android `NORMFILEURL` and `NORMNATIVEURL`\n     * are interchangeable.\n     */\n    NORMFILEURL = 0,\n    /**\n     * Normal processing from a native URL. Since this source type uses deprecated\n     * OS APIs to interact with the camera plugin, it is best avoided, especially\n     * if ongoing forward compatibility is a concern. For further information, see\n     * https://github.com/NeutrinosPlatform/cordova-plugin-mobile-ocr#plugin-usage\n     * Under Android, this is equivalent to `NORMFILEURL`.\n     */\n    NORMNATIVEURL = 1,\n    /**\n     * Fast processing from a file URL. As the compression done internally causes\n     * a significant loss in extraction quality, it should only be preferred when\n     * dealing with large images containing significant amounts of text, where\n     * the execution time required to perform normal processing is prohibitive.\n     * The distinction between file and native URLs is only relevant on iOS;\n     * under Android `FASTFILEURL` and `FASTNATIVEURL` are interchangeable.\n     */\n    FASTFILEURL = 2,\n    /**\n     * Fast processing from a native URL. See comments above for `FASTFILEURL`\n     * concerning quality loss.\n     *\n     * The distinction between file and native URLs is only relevant on iOS;\n     * under Android `FASTFILEURL` and `FASTNATIVEURL` are interchangeable.\n     */\n    FASTNATIVEURL = 3,\n    /**\n     * Normal processing from a base64-encoded string. Quality is equivalent\n     * to `NORMFILEURL`, but due to significantly higher memory requirements,\n     * is only appropriate for use with very small images.\n     */\n    BASE64 = 4\n}\n/**\n * Four points (ordered in clockwise direction) that enclose a text\n * component. May not be axis-aligned due to perspective skew.\n */\nexport interface OCRCorners {\n    x1: number;\n    y1: number;\n    x2: number;\n    y2: number;\n    x3: number;\n    y3: number;\n    x4: number;\n    y4: number;\n}\n/**\n * An axis-aligned bounding rectangle. `x` and `y` represent the top left.\n */\nexport interface OCRRect {\n    x: number;\n    y: number;\n    height: number;\n    width: number;\n}\n/**\n * This is the return value from the `recText` method.\n */\nexport interface OCRResult {\n    /**\n     * Was any text extracted? If `foundText` is false, no other fields are\n     * returned. If foundText is true, all other fields are reliable.\n     */\n    foundText: boolean;\n    /**\n     * A block is the largest unit of text, which can be thought of as a paragraph.\n     * This field consists of several parallel arrays, so the text in `blocktext[0]`\n     * is bounded by `blockpoints[0]` and `blockframe[0]`.\n     */\n    blocks: {\n        blocktext: string[];\n        blockpoints: OCRCorners[];\n        blockframe: OCRRect[];\n    };\n    /**\n     * A line is the central unit of text, containing several elements. A block\n     * can contain N lines. This field consists of several parallel arrays, so the\n     * text in `linetext[0]` is bounded by `linepoints[0]` and `lineframe[0]`.\n     */\n    lines: {\n        linetext: string[];\n        linepoints: OCRCorners[];\n        lineframe: OCRRect[];\n    };\n    /**\n     * A word (or element) is the smallest unit of text. This field consists of\n     * several parallel arrays, so the text in `wordtext[0]` is bounded by\n     * `wordpoints[0]` and `wordframe[0]`.\n     */\n    words: {\n        wordtext: string[];\n        wordpoints: OCRCorners[];\n        wordframe: OCRRect[];\n    };\n}\n/**\n * @name OCR\n * @description\n * This plugin attempts to identify and extract text from an image.\n * Please note: This plugin depends on the GoogleMobileVision pod which is referencing UIWebview, that has been deprecated by Apple.\n * Don't use this plugin in an app intended for App Store as you will get a review rejection from Apple: `Deprecated API Usage â€” Apple will stop accepting submissions of apps that use UIWebView APIs`\n * For more info, please see the following Github issue [Google Mobile Vision relying on deprecated UIWebview](https://github.com/NeutrinosPlatform/cordova-plugin-mobile-ocr/issues/27).\n * @usage\n * ```typescript\n * import { OCR, OCRSourceType } from '@ionic-native/ocr/ngx';\n *\n *\n * constructor(private ocr: OCR) { }\n *\n * ...\n *\n * this.ocr.recText(OCRSourceType.NORMFILEURL, \"file://path/to/image.png\")\n *   .then((res: OCRResult) => console.log(JSON.stringify(res)))\n *   .catch((error: any) => console.error(error));\n *\n * ```\n *\n * @interfaces\n * OCRCorners\n * OCRRect\n * OCRResult\n *\n * @enums\n * OCRSourceType\n */\nexport declare class OCR extends IonicNativePlugin {\n    /**\n     * Extract text from image\n     * @param sourceType {OCRSourceType} type of image source\n     * @param source {string} image source (either file URL or base64 string)\n     * @return {Promise<OCRResult>} extracted text and geometry\n     */\n    recText(sourceType: OCRSourceType, source: string): Promise<OCRResult>;\n}\n"]}